{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReInvent 2019 Amazon Personalize Workshop\n",
    "\n",
    "![MainDiagram](static/imgs/image.png)\n",
    "\n",
    "## Agenda\n",
    "\n",
    "At a high level working with Amazon Personalize follows the steps in the diagram below:\n",
    "\n",
    "![FlowDiagram](static/imgs/personalize_process.png)\n",
    "\n",
    "The specific process that you will be following is:\n",
    "\n",
    "1. Imports and Setup\n",
    "1. Preparing Your Data\n",
    "1. Importing Your Data\n",
    "1. Selecting a Recipe\n",
    "1. Training a Solution\n",
    "1. Deploying a Campaign\n",
    "1. Getting Recommendations\n",
    "1. Real-Time Interactions\n",
    "1. Conclusion\n",
    "1. Bonus: Bulk Export of Recommendations\n",
    "\n",
    "In each of these steps you'll see and execute code snippets written in Python using our Boto3 SDK, these snippets can be modified to be components of your production integration with Personalize. \n",
    "\n",
    "This notebook will walk you through the steps to build a recommendation model for movies that are tailored to specific users, the goal is to recommend movies based on that users' history of positive interactions with movies.\n",
    "\n",
    "The data is provided via the [MovieLens Project](https://movielens.org), you can read more about it later if you are interested.\n",
    "\n",
    "The content below has been written to guide you through the process within the timeline of a workshop session. You can deploy the CloudFormation template you found on GitHub later to your own account and can walk through notebooks 1-3 to do the same exercise again. Additionally you can update the content in the cells to reflect your own data and it is an effective path to building a custom recommendaiton model for your use case.\n",
    "\n",
    "## How to Use the Notebook\n",
    "\n",
    "Code is broken up into cells like the one below. There's a triangular `Run` button at the top of this page you can click to execute each cell and move onto the next, or you can press `Shift` + `Enter` or `Shift` + `Return`(Mac Users) while in the cell to execute it and move onto the next one.\n",
    "\n",
    "\n",
    "As a cell is executing you'll notice a line to the side showcase an `*` while the cell is running or it will update to a number to indicate the last cell that completed executing after it has finished exectuting all the code within a cell.\n",
    "\n",
    "\n",
    "Simply follow the instructions below and execute the cells to get started with Amazon Personalize.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup \n",
    "\n",
    "Python ships with a broad collection of libraries and we need to import those as well as the ones installed to help us like boto3(The AWS SDK) and Pandas/Numpy which are core data science tools. The cell below will import them for use here. It will also update the boto3 library to the latest version. You may see a warning(yellow text) or an error(red text), this is perfectly fine, just continue running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.10.28)\n",
      "Requirement not upgraded as not directly required: s3transfer<0.3.0,>=0.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3) (0.2.1)\n",
      "Requirement not upgraded as not directly required: botocore<1.14.0,>=1.13.28 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3) (1.13.28)\n",
      "Requirement not upgraded as not directly required: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3) (0.9.4)\n",
      "Requirement not upgraded as not directly required: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.28->boto3) (1.23)\n",
      "Requirement not upgraded as not directly required: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.28->boto3) (2.7.3)\n",
      "Requirement not upgraded as not directly required: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.28->boto3) (0.14)\n",
      "Requirement not upgraded as not directly required: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.28->boto3) (1.11.0)\n",
      "\u001b[31mawscli 1.16.283 has requirement botocore==1.13.19, but you'll have botocore 1.13.28 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Update boto3\n",
    "!pip install --upgrade boto3\n",
    "# Imports\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you will want to validate that your environment can communicate successfully with Amazon Personalize, the lines below do just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the SDK to Personalize:\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')\n",
    "personalize_events = boto3.client(service_name='personalize-events')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Your Data\n",
    "\n",
    "To begin you will need a collection of data points where users have interacted with content in some way. Amazon Personalize assumes that if an interaction is recorded it is a positive one, you will see how we use that later. \n",
    "\n",
    "The cell below will download the data you need, extract the content from a Zip file, and then display a small portion of it to your screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-11-29 00:49:30--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 304 Not Modified\n",
      "File ‘ml-100k.zip’ not modified on server. Omitting download.\n",
      "\n",
      "Archive:  ml-100k.zip\n",
      "  inflating: ml-100k/allbut.pl       \n",
      "  inflating: ml-100k/mku.sh          \n",
      "  inflating: ml-100k/README          \n",
      "  inflating: ml-100k/u.data          \n",
      "  inflating: ml-100k/u.genre         \n",
      "  inflating: ml-100k/u.info          \n",
      "  inflating: ml-100k/u.item          \n",
      "  inflating: ml-100k/u.occupation    \n",
      "  inflating: ml-100k/u.user          \n",
      "  inflating: ml-100k/u1.base         \n",
      "  inflating: ml-100k/u1.test         \n",
      "  inflating: ml-100k/u2.base         \n",
      "  inflating: ml-100k/u2.test         \n",
      "  inflating: ml-100k/u3.base         \n",
      "  inflating: ml-100k/u3.test         \n",
      "  inflating: ml-100k/u4.base         \n",
      "  inflating: ml-100k/u4.test         \n",
      "  inflating: ml-100k/u5.base         \n",
      "  inflating: ml-100k/u5.test         \n",
      "  inflating: ml-100k/ua.base         \n",
      "  inflating: ml-100k/ua.test         \n",
      "  inflating: ml-100k/ub.base         \n",
      "  inflating: ml-100k/ub.test         \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>RATING</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>882399156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "      <td>879959583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       USER_ID  ITEM_ID  RATING  TIMESTAMP\n",
       "0          196      242       3  881250949\n",
       "1          186      302       3  891717742\n",
       "...        ...      ...     ...        ...\n",
       "99998       13      225       2  882399156\n",
       "99999       12      203       3  879959583\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wget -N http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip -o ml-100k.zip\n",
    "data = pd.read_csv('./ml-100k/u.data', sep='\\t', names=['USER_ID', 'ITEM_ID', 'RATING', 'TIMESTAMP'], engine='python')\n",
    "pd.set_option('display.max_rows', 5)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the data contains a UserID, ItemID, Rating, and Timestamp.\n",
    "\n",
    "We do not need the `Rating` column so it will be removed before we save the file.\n",
    "\n",
    "Once the data has been prepared you will save it to a CSV file locally with the last line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['USER_ID', 'ITEM_ID', 'TIMESTAMP']] # select columns that match the columns in the schema below\n",
    "filename = \"movie-lens-ml-100k-prepared.csv\"\n",
    "data.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can upload the data into S3 you will need to create a bucket, the cell below will do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "059124553121reinventpersonalizeworkshop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '6AF4232B49FAE9B2',\n",
       "  'HostId': 'G52SzCnu9N3mody2YNOOK8EkVN+/1yRV2rs65BskFzWBOwWSViLHJpGkot1Fx8582IqA2TkGBUk=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'G52SzCnu9N3mody2YNOOK8EkVN+/1yRV2rs65BskFzWBOwWSViLHJpGkot1Fx8582IqA2TkGBUk=',\n",
       "   'x-amz-request-id': '6AF4232B49FAE9B2',\n",
       "   'date': 'Fri, 29 Nov 2019 00:50:39 GMT',\n",
       "   'location': '/059124553121reinventpersonalizeworkshop',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Location': '/059124553121reinventpersonalizeworkshop'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "bucket_name = account_id + \"reinventpersonalizeworkshop\"\n",
    "print(bucket_name)\n",
    "s3.create_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can upload the file to S3 and it will be ready to import into Amazon Personalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(filename).upload_file(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Your Data\n",
    "\n",
    "The steps for importing your data are:\n",
    "\n",
    "1. Create a Dataset Group.\n",
    "1. Determine the schema for your dataset.\n",
    "1. Create a Dataset using your schema.\n",
    "1. Run an ImportJob to load the data for use with Personalize.\n",
    "\n",
    "\n",
    "In Amazon Personalize a Dataset Group is how your information is isolated from any other experiment. No information is shared between these groups at all. A Dataset Group can contain your interaction data, item metadata, user metadata, event trackers, solutions, and campaigns. To learn more about them: https://docs.aws.amazon.com/personalize/latest/dg/API_DatasetGroup.html \n",
    "\n",
    "Begin by creating a Dataset Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataset Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"datasetGroupArn\": \"arn:aws:personalize:us-east-1:059124553121:dataset-group/personalize-RI-demo\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"d781f6c8-6845-43b6-bba4-e991479fbb76\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Fri, 29 Nov 2019 00:50:46 GMT\",\n",
      "      \"x-amzn-requestid\": \"d781f6c8-6845-43b6-bba4-e991479fbb76\",\n",
      "      \"content-length\": \"98\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "create_dataset_group_response = personalize.create_dataset_group(\n",
    "    name = \"personalize-RI-demo\"\n",
    ")\n",
    "\n",
    "dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "print(json.dumps(create_dataset_group_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Group Create Loop\n",
    "\n",
    "It takes a few seconds to create a DatasetGroup so the cell below will poll until the DatasetGroup is active and you can continue with the workshop. Once it says `ACTIVE` move to the `Create Schema` step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetGroup: ACTIVE\n"
     ]
    }
   ],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize.describe_dataset_group(\n",
    "        datasetGroupArn = dataset_group_arn\n",
    "    )\n",
    "    status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
    "    print(\"DatasetGroup: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Schema\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can determine the Schema for your Dataset. In this workshop time is limited so you will only be utilizing user-item-interaction data or interaction data for short. The cell below contains the required items for this dataset and maps to the structure of the CSV that you uploaded earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will create a schema inside Amazon Personalize that can be connected to a Dataset this is how Personalize understands the content within your CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"schemaArn\": \"arn:aws:personalize:us-east-1:059124553121:schema/personalize-ri-demo-schema\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"5c5d9f3b-b826-4bc9-9ed9-e1cfb55ebc59\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Fri, 29 Nov 2019 00:52:37 GMT\",\n",
      "      \"x-amzn-requestid\": \"5c5d9f3b-b826-4bc9-9ed9-e1cfb55ebc59\",\n",
      "      \"content-length\": \"92\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "create_schema_response = personalize.create_schema(\n",
    "    name = \"personalize-ri-demo-schema\",\n",
    "    schema = json.dumps(schema)\n",
    ")\n",
    "\n",
    "schema_arn = create_schema_response['schemaArn']\n",
    "print(json.dumps(create_schema_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next create the Dataset for interactions and assign it the Schema provided and assign it to the Dataset Group you created earlier with this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"datasetArn\": \"arn:aws:personalize:us-east-1:059124553121:dataset/personalize-RI-demo/INTERACTIONS\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"194334f7-1363-404e-9c0b-8a3f7f4fff82\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Fri, 29 Nov 2019 00:52:39 GMT\",\n",
      "      \"x-amzn-requestid\": \"194334f7-1363-404e-9c0b-8a3f7f4fff82\",\n",
      "      \"content-length\": \"100\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "dataset_type = \"INTERACTIONS\"\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    name = \"personalize-ri-interactions\",\n",
    "    datasetType = dataset_type,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    schemaArn = schema_arn\n",
    ")\n",
    "\n",
    "dataset_arn = create_dataset_response['datasetArn']\n",
    "print(json.dumps(create_dataset_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attach Policy to S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can execute the import job for your data you will need to attach a bucket policy to your S3 bucket to allow Personalize to communicate with it, as well as an IAM role for the service to use within this AWS account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'CFF77C150CEF952A',\n",
       "  'HostId': 'bmCCX7U940Zc5GyR/u7QG5+GcKmgPhRA+LCeUEeGKQh2AgvdmroEFjT2zqt8W8Vzgv3KPPQlmMg=',\n",
       "  'HTTPStatusCode': 204,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'bmCCX7U940Zc5GyR/u7QG5+GcKmgPhRA+LCeUEeGKQh2AgvdmroEFjT2zqt8W8Vzgv3KPPQlmMg=',\n",
       "   'x-amz-request-id': 'CFF77C150CEF952A',\n",
       "   'date': 'Fri, 29 Nov 2019 00:52:46 GMT',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:*Object\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(bucket_name),\n",
    "                \"arn:aws:s3:::{}/*\".format(bucket_name)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "s3.put_bucket_policy(Bucket=bucket_name, Policy=json.dumps(policy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a note, IAM changes in the cell below take just a few seconds to be confirmed so this section will take 1 minute to complete. Execute the cell below next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Personalize Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::059124553121:role/PersonalizeRoleRIDemo\n"
     ]
    }
   ],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = \"PersonalizeRoleRIDemo\"\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"personalize.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName = role_name,\n",
    "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    ")\n",
    "\n",
    "# AmazonPersonalizeFullAccess provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n",
    "# if you would like to use a bucket with a different name, please consider creating and attaching a new policy\n",
    "# that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\n",
    "policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\"\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = policy_arn\n",
    ")\n",
    "\n",
    "# Now add S3 support\n",
    "iam.attach_role_policy(\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "    RoleName=role_name\n",
    ")\n",
    "time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last you are ready to import the data into Personalize, the first cell below will start the process and the second contains a while loop that will poll the service to determine when the import job has completed. \n",
    "\n",
    "During this workshop you are importing a relatively small dataset and it may seem like this takes a while for such a small file. The leading use of time here is provisioning dedicated resources that will actually run the task. This allows Personalize to provide HIPAA compliance for example, it also means that just because your files are larger that it won't take an extremely long time, once the resources are up and running the import is pretty quick.\n",
    "\n",
    "It may take up to 20 minutes for the import process to complete. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataset Import Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"datasetImportJobArn\": \"arn:aws:personalize:us-east-1:059124553121:dataset-import-job/personalize-ri-import\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"d8c3927f-0149-4b94-b8e2-5b73fbcd0814\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Fri, 29 Nov 2019 00:56:03 GMT\",\n",
      "      \"x-amzn-requestid\": \"d8c3927f-0149-4b94-b8e2-5b73fbcd0814\",\n",
      "      \"content-length\": \"109\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName = \"personalize-ri-import\",\n",
    "    datasetArn = dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": \"s3://{}/{}\".format(bucket_name, filename)\n",
    "    },\n",
    "    roleArn = role_arn\n",
    ")\n",
    "\n",
    "dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Import Loop\n",
    "\n",
    "The cell below will take a bit longer to complete, it is polling to learn when your Dataset has been fully imported into Personalize. This should take around 20 minutes to complete. Most of the time is spent provisioning infrastructure behind the scenes. This means that much larger files do not take much longer to import in most cases.\n",
    "\n",
    "Run the cell below, then move on when it reaches an `ACTIVE` state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Started on:  12:56:21 AM\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: ACTIVE\n",
      "Import Completed on:  01:12:23 AM\n"
     ]
    }
   ],
   "source": [
    "current_time = datetime.datetime.now()\n",
    "print(\"Import Started on: \", current_time.strftime(\"%I:%M:%S %p\"))\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = dataset_import_job_arn\n",
    "    )\n",
    "    status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    print(\"DatasetImportJob: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "    \n",
    "current_time = datetime.datetime.now()\n",
    "print(\"Import Completed on: \", current_time.strftime(\"%I:%M:%S %p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a Recipe\n",
    "\n",
    "Inside Personalize the algorithms available are called recipes, the code below will give you a full list of them. They each have various use cases and detailed information can be found here: https://docs.aws.amazon.com/personalize/latest/dg/working-with-predefined-recipes.html\n",
    "\n",
    "In this workshop you will be using HRNN(Hierarchical Recurrent Neural Network) quoting the docs:\n",
    "\n",
    "```\n",
    "HRRN is a hierarchical recurrent neural network, which can model the user-item interactions across a given timeframe. Use the HRNN recipe when user behavior changes over time, which is referred to the evolving intent problem.\n",
    "\n",
    "To train a model, HRNN uses the Interactions dataset from a dataset group. A dataset group is a set of related datasets, which can include the Users, Items, and Interactions datasets.\n",
    "```\n",
    "\n",
    "A paper explaining it more in detail as it relates to recommendations: https://openreview.net/pdf?id=ByzxsrrkJ4 \n",
    "\n",
    "\n",
    "It is used here as an example of a recommendation system built using deep neural networks and can be trained using only our interactions data. This is a great place to start when running your own experiments later as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recipes': [{'name': 'aws-hrnn',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-hrnn',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2019, 6, 20, 0, 39, 17, 65000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-hrnn-coldstart',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-hrnn-coldstart',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2019, 6, 20, 0, 39, 17, 64000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-hrnn-metadata',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-hrnn-metadata',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2019, 6, 20, 0, 39, 17, 64000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-personalized-ranking',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-personalized-ranking',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2019, 6, 20, 0, 39, 17, 65000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-popularity-count',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-popularity-count',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2019, 6, 20, 0, 39, 17, 65000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-sims',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-sims',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2019, 6, 20, 0, 39, 17, 64000, tzinfo=tzlocal())}],\n",
       " 'ResponseMetadata': {'RequestId': '3ad3fc5f-6d74-4738-8972-3c1ab216111a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Fri, 29 Nov 2019 01:21:12 GMT',\n",
       "   'x-amzn-requestid': '3ad3fc5f-6d74-4738-8972-3c1ab216111a',\n",
       "   'content-length': '1067',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personalize.list_recipes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below selects the `HRNN` recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_arn = \"arn:aws:personalize:::recipe/aws-hrnn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Solution\n",
    "\n",
    "Within Amazon Personalize a model trained on customer data is called a Solution, these are versioned and so you will first create a Solution, then a Solution Version. The versions are utilized to track model improvement over time based on newer available data. \n",
    "\n",
    "Creating a Solution itself is nearly instantaneous however the actual training to create a version can take a bit of time. This is usually the longest waiting period in the process. If you are doing this outside of a workshop it is a great time to check your emails, grab a coffee, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"solutionArn\": \"arn:aws:personalize:us-east-1:059124553121:solution/personalize-ri-soln-hrnn\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"2aa1f40d-5815-4d98-8250-2e14d7db8666\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Fri, 29 Nov 2019 01:21:14 GMT\",\n",
      "      \"x-amzn-requestid\": \"2aa1f40d-5815-4d98-8250-2e14d7db8666\",\n",
      "      \"content-length\": \"94\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "create_solution_response = personalize.create_solution(\n",
    "    name = \"personalize-ri-soln-hrnn\",\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    recipeArn = recipe_arn\n",
    ")\n",
    "\n",
    "solution_arn = create_solution_response['solutionArn']\n",
    "print(json.dumps(create_solution_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Solution Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"solutionVersionArn\": \"arn:aws:personalize:us-east-1:059124553121:solution/personalize-ri-soln-hrnn/da0717fb\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"a75a5b00-f530-42a3-bc55-9c2ee17e2751\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Fri, 29 Nov 2019 01:21:16 GMT\",\n",
      "      \"x-amzn-requestid\": \"a75a5b00-f530-42a3-bc55-9c2ee17e2751\",\n",
      "      \"content-length\": \"110\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "create_solution_version_response = personalize.create_solution_version(\n",
    "    solutionArn = solution_arn\n",
    ")\n",
    "\n",
    "solution_version_arn = create_solution_version_response['solutionVersionArn']\n",
    "print(json.dumps(create_solution_version_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Solution Version Loop\n",
    "\n",
    "Training a model can take a bit of time, this will often take at least 20 minutes to complete. Run the cell below, again waiting for it to reach an `ACTIVE` state before moving to the next bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started on:  01:21:17 AM\n",
      "SolutionVersion: CREATE PENDING\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: CREATE IN_PROGRESS\n",
      "SolutionVersion: ACTIVE\n",
      "Training Completed on:  02:00:20 AM\n"
     ]
    }
   ],
   "source": [
    "current_time = datetime.datetime.now()\n",
    "print(\"Training Started on: \", current_time.strftime(\"%I:%M:%S %p\"))\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_solution_version_response = personalize.describe_solution_version(\n",
    "        solutionVersionArn = solution_version_arn\n",
    "    )\n",
    "    status = describe_solution_version_response[\"solutionVersion\"][\"status\"]\n",
    "    print(\"SolutionVersion: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "    \n",
    "current_time = datetime.datetime.now()\n",
    "print(\"Training Completed on: \", current_time.strftime(\"%I:%M:%S %p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Metrics of Solution Version\n",
    "\n",
    "Now that your solution and version exists, you can obtain the metrics for it to judge its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"solutionVersionArn\": \"arn:aws:personalize:us-east-1:059124553121:solution/personalize-ri-soln-hrnn/da0717fb\",\n",
      "  \"metrics\": {\n",
      "    \"coverage\": 0.3445,\n",
      "    \"mean_reciprocal_rank_at_25\": 0.0349,\n",
      "    \"normalized_discounted_cumulative_gain_at_10\": 0.0551,\n",
      "    \"normalized_discounted_cumulative_gain_at_25\": 0.071,\n",
      "    \"normalized_discounted_cumulative_gain_at_5\": 0.0408,\n",
      "    \"precision_at_10\": 0.0101,\n",
      "    \"precision_at_25\": 0.0067,\n",
      "    \"precision_at_5\": 0.0112\n",
      "  },\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"36453efa-ed36-488e-879f-4458c38b7dfc\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Fri, 29 Nov 2019 02:00:28 GMT\",\n",
      "      \"x-amzn-requestid\": \"36453efa-ed36-488e-879f-4458c38b7dfc\",\n",
      "      \"content-length\": \"407\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "get_solution_metrics_response = personalize.get_solution_metrics(\n",
    "    solutionVersionArn = solution_version_arn\n",
    ")\n",
    "\n",
    "print(json.dumps(get_solution_metrics_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Wait for the Campaign\n",
    "\n",
    "Now that you have a working solution version you will need to create a campaign to use it with your applications. A campaign is simply a hosted copy of your model. Again there will be a short wait so after executing you can take a quick break while the infrastructure is being provisioned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"campaignArn\": \"arn:aws:personalize:us-east-1:059124553121:campaign/personalize-ri-camp\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"c45094c9-db02-4edb-8b00-28c2390e1387\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Fri, 29 Nov 2019 02:00:29 GMT\",\n",
      "      \"x-amzn-requestid\": \"c45094c9-db02-4edb-8b00-28c2390e1387\",\n",
      "      \"content-length\": \"89\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "create_campaign_response = personalize.create_campaign(\n",
    "    name = \"personalize-ri-camp\",\n",
    "    solutionVersionArn = solution_version_arn,\n",
    "    minProvisionedTPS = 1\n",
    ")\n",
    "\n",
    "campaign_arn = create_campaign_response['campaignArn']\n",
    "print(json.dumps(create_campaign_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for Campaign to Have ACTIVE Status\n",
    "\n",
    "#### Create a Campaign Loop\n",
    "\n",
    "In this section Personalize is deploying your model and that takes a few minutes to complete. Execute the cell below to agian poll until the task has completed. It should take 10 to 15 minutes. Once the cell has reached an `ACTIVE` state, continue on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying Started on:  02:00:31 AM\n",
      "Campaign: CREATE PENDING\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: ACTIVE\n",
      "Deploying Completed on:  02:10:32 AM\n"
     ]
    }
   ],
   "source": [
    "current_time = datetime.datetime.now()\n",
    "print(\"Deploying Started on: \", current_time.strftime(\"%I:%M:%S %p\"))\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_campaign_response = personalize.describe_campaign(\n",
    "        campaignArn = campaign_arn\n",
    "    )\n",
    "    status = describe_campaign_response[\"campaign\"][\"status\"]\n",
    "    print(\"Campaign: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "    \n",
    "current_time = datetime.datetime.now()\n",
    "print(\"Deploying Completed on: \", current_time.strftime(\"%I:%M:%S %p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sample Recommendations\n",
    "\n",
    "After the campaign is active you are ready to get recommendations. First we need to select a random user from the collection. Then we will create a few helper functions for getting movie information to show for recommendations instead of just IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: 472\n"
     ]
    }
   ],
   "source": [
    "# Getting a random user:\n",
    "user_id, item_id, _ = data.sample().values[0]\n",
    "print(\"USER: {}\".format(user_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv('./ml-100k/u.item', sep='|', usecols=[0,1], encoding='latin-1', names=['ITEM_ID', 'TITLE'], index_col='ITEM_ID')\n",
    "\n",
    "def get_movie_title(movie_id):\n",
    "    \"\"\"\n",
    "    Takes in an ID, returns a title\n",
    "    \"\"\"\n",
    "    movie_id = int(movie_id)\n",
    "    return items.iloc[movie_id]['TITLE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select a User and an Item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call GetRecommendations\n",
    "\n",
    "The code below will get recommendations for the random user selected, it then places the recommendations in a dataframe and renders it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user:  472\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blade Runner (1982)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go Fish (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White Balloon, The (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Congo (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Little Odessa (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sleepers (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Misérables, Les (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jane Eyre (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wild Bunch, The (1969)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shawshank Redemption, The (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Maverick (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Shanghai Triad (Yao a yao yao dao waipo qiao) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Glengarry Glen Ross (1992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ace Ventura: Pet Detective (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bio-Dome (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Big Blue, The (Grand bleu, Le) (1988)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fargo (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Just Cause (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Faster Pussycat! Kill! Kill! (1965)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Batman (1989)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Aladdin (1992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mission: Impossible (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Original Recommendations\n",
       "0                                 Blade Runner (1982)\n",
       "1                                      Go Fish (1994)\n",
       "2                           White Balloon, The (1995)\n",
       "3                  Father of the Bride Part II (1995)\n",
       "4                                        Congo (1995)\n",
       "5                                Little Odessa (1994)\n",
       "6                                     Sleepers (1996)\n",
       "7                              Misérables, Les (1995)\n",
       "8                                    Jane Eyre (1996)\n",
       "9                              Wild Bunch, The (1969)\n",
       "10                   Shawshank Redemption, The (1994)\n",
       "11                                    Maverick (1994)\n",
       "12  Shanghai Triad (Yao a yao yao dao waipo qiao) ...\n",
       "13                         Glengarry Glen Ross (1992)\n",
       "14                  Ace Ventura: Pet Detective (1994)\n",
       "15                                    Bio-Dome (1996)\n",
       "16              Big Blue, The (Grand bleu, Le) (1988)\n",
       "17                                       Fargo (1996)\n",
       "18                                  Just Cause (1995)\n",
       "19                Faster Pussycat! Kill! Kill! (1965)\n",
       "20                                      Batman (1989)\n",
       "21                                     Aladdin (1992)\n",
       "22                         Mission: Impossible (1996)\n",
       "23                                   Star Wars (1977)\n",
       "24                                  Four Rooms (1995)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    campaignArn = campaign_arn,\n",
    "    userId = str(user_id),\n",
    ")\n",
    "# Update DF rendering\n",
    "pd.set_option('display.max_rows', 30)\n",
    "\n",
    "print(\"Recommendations for user: \", user_id)\n",
    "\n",
    "item_list = get_recommendations_response['itemList']\n",
    "\n",
    "recommendation_list = []\n",
    "\n",
    "for item in item_list:\n",
    "    title = get_movie_title(item['itemId'])\n",
    "    recommendation_list.append(title)\n",
    "    \n",
    "recommendations_df = pd.DataFrame(recommendation_list, columns = ['Original Recommendations'])\n",
    "recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Event Tracker\n",
    "\n",
    "Before your recommendation system can respond to real time events you will need an event tracker, the code below will generate one and can be used going forward with this lab. Feel free to name it something more clever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:personalize:us-east-1:059124553121:event-tracker/2a0e0f0d\n",
      "d321b1b2-bdf0-4ee2-bb99-af19555e2ccc\n"
     ]
    }
   ],
   "source": [
    "response = personalize.create_event_tracker(\n",
    "    name='MovieClickTrackerRI',\n",
    "    datasetGroupArn=dataset_group_arn\n",
    ")\n",
    "print(response['eventTrackerArn'])\n",
    "print(response['trackingId'])\n",
    "TRACKING_ID = response['trackingId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_tracker_arn = response['eventTrackerArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating User Behavior\n",
    "\n",
    "The lines below provide a code sample that simulates a user interacting with a particular item, you will then get recommendations that differ from those when you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_movie_click(USER_ID, ITEM_ID):\n",
    "    \"\"\"\n",
    "    Simulates a click as an envent\n",
    "    to send an event to Amazon Personalize's Event Tracker\n",
    "    \"\"\"\n",
    "    # Configure Session\n",
    "    try:\n",
    "        session_ID = session_dict[USER_ID]\n",
    "    except:\n",
    "        session_dict[USER_ID] = str(uuid.uuid1())\n",
    "        session_ID = session_dict[USER_ID]\n",
    "        \n",
    "    # Configure Properties:\n",
    "    event = {\n",
    "    \"itemId\": str(ITEM_ID),\n",
    "    }\n",
    "    event_json = json.dumps(event)\n",
    "        \n",
    "    # Make Call\n",
    "    personalize_events.put_events(\n",
    "    trackingId = TRACKING_ID,\n",
    "    userId= USER_ID,\n",
    "    sessionId = session_ID,\n",
    "    eventList = [{\n",
    "        'sentAt': int(time.time()),\n",
    "        'eventType': 'EVENT_TYPE',\n",
    "        'properties': event_json\n",
    "        }]\n",
    "    )\n",
    "\n",
    "def get_new_recommendations_df(recommendations_df, movie_ID):\n",
    "    # Get the title of the movie for the header of the column\n",
    "    movie_title_clicked = get_movie_title(movie_to_click)\n",
    "    # Interact with the movie\n",
    "    send_movie_click(USER_ID=str(user_id), ITEM_ID=movie_to_click)\n",
    "    # Sleep for 2 seconds\n",
    "    time.sleep(2)\n",
    "    # Get new recommendations\n",
    "    get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "        campaignArn = campaign_arn,\n",
    "        userId = str(user_id),\n",
    "    )\n",
    "    # Build a new dataframe of recommendations\n",
    "    item_list = get_recommendations_response['itemList']\n",
    "    recommendation_list = []\n",
    "    for item in item_list:\n",
    "        title = get_movie_title(item['itemId'])\n",
    "        recommendation_list.append(title)\n",
    "    new_rec_DF = pd.DataFrame(recommendation_list, columns = [movie_title_clicked])\n",
    "    # Add this dataframe to the old one\n",
    "    recommendations_df = recommendations_df.join(new_rec_DF)\n",
    "    return recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will execute interactions and update the dataframe with the results so you can see the overall impact. Feel free to run the cell several times with movie IDs less than 1000. Note for this demo it will error if you use the same movie twice, this is due to how we showcase the headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Recommendations</th>\n",
       "      <th>Return of the Jedi (1983)</th>\n",
       "      <th>Delicatessen (1991)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blade Runner (1982)</td>\n",
       "      <td>Go Fish (1994)</td>\n",
       "      <td>Raiders of the Lost Ark (1981)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go Fish (1994)</td>\n",
       "      <td>Wild Bunch, The (1969)</td>\n",
       "      <td>Ridicule (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White Balloon, The (1995)</td>\n",
       "      <td>Fargo (1996)</td>\n",
       "      <td>Bram Stoker's Dracula (1992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Terminator 2: Judgment Day (1991)</td>\n",
       "      <td>Blade Runner (1982)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Congo (1995)</td>\n",
       "      <td>Blade Runner (1982)</td>\n",
       "      <td>Weekend at Bernie's (1989)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Little Odessa (1994)</td>\n",
       "      <td>Robert A. Heinlein's The Puppet Masters (1994)</td>\n",
       "      <td>Fargo (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sleepers (1996)</td>\n",
       "      <td>Unbearable Lightness of Being, The (1988)</td>\n",
       "      <td>Godfather: Part II, The (1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Misérables, Les (1995)</td>\n",
       "      <td>Ghost and the Darkness, The (1996)</td>\n",
       "      <td>Mighty Aphrodite (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jane Eyre (1996)</td>\n",
       "      <td>Bio-Dome (1996)</td>\n",
       "      <td>M*A*S*H (1970)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wild Bunch, The (1969)</td>\n",
       "      <td>Bram Stoker's Dracula (1992)</td>\n",
       "      <td>Dirty Dancing (1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shawshank Redemption, The (1994)</td>\n",
       "      <td>Wolf (1994)</td>\n",
       "      <td>Wild Bunch, The (1969)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Maverick (1994)</td>\n",
       "      <td>Ace Ventura: Pet Detective (1994)</td>\n",
       "      <td>Dances with Wolves (1990)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Shanghai Triad (Yao a yao yao dao waipo qiao) ...</td>\n",
       "      <td>Dirty Dancing (1987)</td>\n",
       "      <td>Big Blue, The (Grand bleu, Le) (1988)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Glengarry Glen Ross (1992)</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Robert A. Heinlein's The Puppet Masters (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ace Ventura: Pet Detective (1994)</td>\n",
       "      <td>Godfather: Part II, The (1974)</td>\n",
       "      <td>Shadowlands (1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bio-Dome (1996)</td>\n",
       "      <td>Weekend at Bernie's (1989)</td>\n",
       "      <td>Brazil (1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Big Blue, The (Grand bleu, Le) (1988)</td>\n",
       "      <td>Dead Man Walking (1995)</td>\n",
       "      <td>Kama Sutra: A Tale of Love (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fargo (1996)</td>\n",
       "      <td>Sophie's Choice (1982)</td>\n",
       "      <td>Snow White and the Seven Dwarfs (1937)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Just Cause (1995)</td>\n",
       "      <td>Mission: Impossible (1996)</td>\n",
       "      <td>Children of the Corn: The Gathering (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Faster Pussycat! Kill! Kill! (1965)</td>\n",
       "      <td>Raiders of the Lost Ark (1981)</td>\n",
       "      <td>Hear My Song (1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Batman (1989)</td>\n",
       "      <td>Faster Pussycat! Kill! Kill! (1965)</td>\n",
       "      <td>Wrong Trousers, The (1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Aladdin (1992)</td>\n",
       "      <td>Mask, The (1994)</td>\n",
       "      <td>Graduate, The (1967)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mission: Impossible (1996)</td>\n",
       "      <td>Indiana Jones and the Last Crusade (1989)</td>\n",
       "      <td>Unbearable Lightness of Being, The (1988)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Star Wars (1977)</td>\n",
       "      <td>Mary Poppins (1964)</td>\n",
       "      <td>Mission: Impossible (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>Ridicule (1996)</td>\n",
       "      <td>Priest (1994)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Original Recommendations  \\\n",
       "0                                 Blade Runner (1982)   \n",
       "1                                      Go Fish (1994)   \n",
       "2                           White Balloon, The (1995)   \n",
       "3                  Father of the Bride Part II (1995)   \n",
       "4                                        Congo (1995)   \n",
       "5                                Little Odessa (1994)   \n",
       "6                                     Sleepers (1996)   \n",
       "7                              Misérables, Les (1995)   \n",
       "8                                    Jane Eyre (1996)   \n",
       "9                              Wild Bunch, The (1969)   \n",
       "10                   Shawshank Redemption, The (1994)   \n",
       "11                                    Maverick (1994)   \n",
       "12  Shanghai Triad (Yao a yao yao dao waipo qiao) ...   \n",
       "13                         Glengarry Glen Ross (1992)   \n",
       "14                  Ace Ventura: Pet Detective (1994)   \n",
       "15                                    Bio-Dome (1996)   \n",
       "16              Big Blue, The (Grand bleu, Le) (1988)   \n",
       "17                                       Fargo (1996)   \n",
       "18                                  Just Cause (1995)   \n",
       "19                Faster Pussycat! Kill! Kill! (1965)   \n",
       "20                                      Batman (1989)   \n",
       "21                                     Aladdin (1992)   \n",
       "22                         Mission: Impossible (1996)   \n",
       "23                                   Star Wars (1977)   \n",
       "24                                  Four Rooms (1995)   \n",
       "\n",
       "                         Return of the Jedi (1983)  \\\n",
       "0                                   Go Fish (1994)   \n",
       "1                           Wild Bunch, The (1969)   \n",
       "2                                     Fargo (1996)   \n",
       "3                Terminator 2: Judgment Day (1991)   \n",
       "4                              Blade Runner (1982)   \n",
       "5   Robert A. Heinlein's The Puppet Masters (1994)   \n",
       "6        Unbearable Lightness of Being, The (1988)   \n",
       "7               Ghost and the Darkness, The (1996)   \n",
       "8                                  Bio-Dome (1996)   \n",
       "9                     Bram Stoker's Dracula (1992)   \n",
       "10                                     Wolf (1994)   \n",
       "11               Ace Ventura: Pet Detective (1994)   \n",
       "12                            Dirty Dancing (1987)   \n",
       "13                      Usual Suspects, The (1995)   \n",
       "14                  Godfather: Part II, The (1974)   \n",
       "15                      Weekend at Bernie's (1989)   \n",
       "16                         Dead Man Walking (1995)   \n",
       "17                          Sophie's Choice (1982)   \n",
       "18                      Mission: Impossible (1996)   \n",
       "19                  Raiders of the Lost Ark (1981)   \n",
       "20             Faster Pussycat! Kill! Kill! (1965)   \n",
       "21                                Mask, The (1994)   \n",
       "22       Indiana Jones and the Last Crusade (1989)   \n",
       "23                             Mary Poppins (1964)   \n",
       "24                                 Ridicule (1996)   \n",
       "\n",
       "                               Delicatessen (1991)  \n",
       "0                   Raiders of the Lost Ark (1981)  \n",
       "1                                  Ridicule (1996)  \n",
       "2                     Bram Stoker's Dracula (1992)  \n",
       "3                              Blade Runner (1982)  \n",
       "4                       Weekend at Bernie's (1989)  \n",
       "5                                     Fargo (1996)  \n",
       "6                   Godfather: Part II, The (1974)  \n",
       "7                          Mighty Aphrodite (1995)  \n",
       "8                                   M*A*S*H (1970)  \n",
       "9                             Dirty Dancing (1987)  \n",
       "10                          Wild Bunch, The (1969)  \n",
       "11                       Dances with Wolves (1990)  \n",
       "12           Big Blue, The (Grand bleu, Le) (1988)  \n",
       "13  Robert A. Heinlein's The Puppet Masters (1994)  \n",
       "14                              Shadowlands (1993)  \n",
       "15                                   Brazil (1985)  \n",
       "16               Kama Sutra: A Tale of Love (1996)  \n",
       "17          Snow White and the Seven Dwarfs (1937)  \n",
       "18      Children of the Corn: The Gathering (1996)  \n",
       "19                             Hear My Song (1991)  \n",
       "20                      Wrong Trousers, The (1993)  \n",
       "21                            Graduate, The (1967)  \n",
       "22       Unbearable Lightness of Being, The (1988)  \n",
       "23                      Mission: Impossible (1996)  \n",
       "24                                   Priest (1994)  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_to_click = 180\n",
    "recommendations_df = get_new_recommendations_df(recommendations_df, movie_to_click)\n",
    "recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this workshop you successfully created a dataset group, a dataset based on interactions, trained a recommendation model based on the data, deployed a campaign to generate recommendations, evaluated the initial recommendations, leveraged real time event tracking for even better recommendations, and below is bonus material to show how to export recommendations in  \n",
    "\n",
    "This content will stay public on GitHub and can be used within your organization in order to build custom recommendation models, take a look at the various other notebooks in the future.\n",
    "\n",
    "Thank you, and good luck in your next Machine Learning project!\n",
    "\n",
    "BONUS MATERIAL BELOW:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Recommendations\n",
    "\n",
    "So far you have seen how to generate recommendations via an API call and interact with event trackers. That works well for many applications but you may find yourself wanting to cache all recommendations for users locally or even to study the recommendations for new ideas. To support that Amazon Personalize supports batch exporting of your recommendations to a file as well. The cells below will walk you through sending recommendations to a file in S3 and then will show its contents. The file can be downloaded from S3 to your local computer as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First you will need to create a JSON file of user IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_IDs = ['561', '233', '579']\n",
    "\n",
    "json_input_filename = \"json_input.json\"\n",
    "with open(json_input_filename, 'w') as json_input:\n",
    "    for user_id in user_IDs:\n",
    "        json_input.write('{\"userId\": \"' + user_id + '\"}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now upload this file to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://059124553121reinventpersonalizeworkshop/json_input.json\n"
     ]
    }
   ],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(json_input_filename).upload_file(json_input_filename)\n",
    "s3_input_path = \"s3://\" + bucket_name + \"/\" + json_input_filename\n",
    "print(s3_input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the input file is available in S3, you need to define where the output will go, and create a batch inference job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://059124553121reinventpersonalizeworkshop/\n"
     ]
    }
   ],
   "source": [
    "s3_output_path = \"s3://\" + bucket_name + \"/\"\n",
    "print(s3_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below creates the batch job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalize_rec = boto3.client(service_name='personalize')\n",
    "batchInferenceJobArn = personalize_rec.create_batch_inference_job (\n",
    "    solutionVersionArn = solution_version_arn,\n",
    "    jobName = \"RI-Workshop-Batch-Inference-Job\",\n",
    "    roleArn = role_arn,\n",
    "    jobInput = \n",
    "     {\"s3DataSource\": {\"path\": s3_input_path}},\n",
    "    jobOutput = \n",
    "     {\"s3DataDestination\":{\"path\": s3_output_path}}\n",
    ")\n",
    "batchInferenceJobArn = batchInferenceJobArn['batchInferenceJobArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will poll until the export has completed. This is the final waiting loop of the workshop! This will again poll until it reaches an `ACTIVE` state, you can continue on once this is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Started on:  02:28:02 AM\n",
      "DatasetInferenceJob: CREATE PENDING\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: CREATE IN_PROGRESS\n",
      "DatasetInferenceJob: ACTIVE\n",
      "Import Completed on:  03:03:04 AM\n"
     ]
    }
   ],
   "source": [
    "current_time = datetime.datetime.now()\n",
    "print(\"Import Started on: \", current_time.strftime(\"%I:%M:%S %p\"))\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_inference_job_response = personalize_rec.describe_batch_inference_job(\n",
    "        batchInferenceJobArn = batchInferenceJobArn\n",
    "    )\n",
    "    status = describe_dataset_inference_job_response[\"batchInferenceJob\"]['status']\n",
    "    print(\"DatasetInferenceJob: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "    \n",
    "current_time = datetime.datetime.now()\n",
    "print(\"Import Completed on: \", current_time.strftime(\"%I:%M:%S %p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data successfully exported, grab the file and parse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User: 561</th>\n",
       "      <th>User: 233</th>\n",
       "      <th>User: 579</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>George of the Jungle (1997)</td>\n",
       "      <td>Ulee's Gold (1997)</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shiloh (1997)</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>Georgia (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Evita (1996)</td>\n",
       "      <td>U Turn (1997)</td>\n",
       "      <td>Bram Stoker's Dracula (1992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L.A. Confidential (1997)</td>\n",
       "      <td>Gattaca (1997)</td>\n",
       "      <td>Man of No Importance, A (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gattaca (1997)</td>\n",
       "      <td>Critical Care (1997)</td>\n",
       "      <td>Blade Runner (1982)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U Turn (1997)</td>\n",
       "      <td>Wings of the Dove, The (1997)</td>\n",
       "      <td>Maverick (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Contact (1997)</td>\n",
       "      <td>Supercop (1992)</td>\n",
       "      <td>Muriel's Wedding (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ulee's Gold (1997)</td>\n",
       "      <td>FairyTale: A True Story (1997)</td>\n",
       "      <td>Jaws 2 (1978)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Marvin's Room (1996)</td>\n",
       "      <td>Breakdown (1997)</td>\n",
       "      <td>Little Odessa (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hoodlum (1997)</td>\n",
       "      <td>George of the Jungle (1997)</td>\n",
       "      <td>Go Fish (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3 Ninjas: High Noon At Mega Mountain (1998)</td>\n",
       "      <td>Evita (1996)</td>\n",
       "      <td>Sleeper (1973)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Breakdown (1997)</td>\n",
       "      <td>L.A. Confidential (1997)</td>\n",
       "      <td>Remains of the Day, The (1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>Tomorrow Never Dies (1997)</td>\n",
       "      <td>True Lies (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Apostle, The (1997)</td>\n",
       "      <td>Babe (1995)</td>\n",
       "      <td>Just Cause (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Critical Care (1997)</td>\n",
       "      <td>Restoration (1995)</td>\n",
       "      <td>Great Race, The (1965)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Austin Powers: International Man of Mystery (1...</td>\n",
       "      <td>Full Monty, The (1997)</td>\n",
       "      <td>Thinner (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>As Good As It Gets (1997)</td>\n",
       "      <td>Dark City (1998)</td>\n",
       "      <td>Crow, The (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hunt for Red October, The (1990)</td>\n",
       "      <td>Desperate Measures (1998)</td>\n",
       "      <td>Some Kind of Wonderful (1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Desperate Measures (1998)</td>\n",
       "      <td>Replacement Killers, The (1998)</td>\n",
       "      <td>Free Willy (1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Leaving Las Vegas (1995)</td>\n",
       "      <td>Jane Eyre (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Game, The (1997)</td>\n",
       "      <td>Contact (1997)</td>\n",
       "      <td>Unforgiven (1992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ice Storm, The (1997)</td>\n",
       "      <td>Starship Troopers (1997)</td>\n",
       "      <td>Baby-Sitters Club, The (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Alien (1979)</td>\n",
       "      <td>Paradise Lost: The Child Murders at Robin Hood...</td>\n",
       "      <td>Beavis and Butt-head Do America (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>My Left Foot (1989)</td>\n",
       "      <td>Flipper (1996)</td>\n",
       "      <td>Bad Boys (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>In &amp; Out (1997)</td>\n",
       "      <td>Jungle2Jungle (1997)</td>\n",
       "      <td>Princess Bride, The (1987)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            User: 561  \\\n",
       "0                         George of the Jungle (1997)   \n",
       "1                                       Shiloh (1997)   \n",
       "2                                        Evita (1996)   \n",
       "3                            L.A. Confidential (1997)   \n",
       "4                                      Gattaca (1997)   \n",
       "5                                       U Turn (1997)   \n",
       "6                                      Contact (1997)   \n",
       "7                                  Ulee's Gold (1997)   \n",
       "8                                Marvin's Room (1996)   \n",
       "9                                      Hoodlum (1997)   \n",
       "10        3 Ninjas: High Noon At Mega Mountain (1998)   \n",
       "11                                   Breakdown (1997)   \n",
       "12                                        Heat (1995)   \n",
       "13                                Apostle, The (1997)   \n",
       "14                               Critical Care (1997)   \n",
       "15  Austin Powers: International Man of Mystery (1...   \n",
       "16                          As Good As It Gets (1997)   \n",
       "17                   Hunt for Red October, The (1990)   \n",
       "18                          Desperate Measures (1998)   \n",
       "19                                     Jumanji (1995)   \n",
       "20                                   Game, The (1997)   \n",
       "21                              Ice Storm, The (1997)   \n",
       "22                                       Alien (1979)   \n",
       "23                                My Left Foot (1989)   \n",
       "24                                    In & Out (1997)   \n",
       "\n",
       "                                            User: 233  \\\n",
       "0                                  Ulee's Gold (1997)   \n",
       "1                                         Heat (1995)   \n",
       "2                                       U Turn (1997)   \n",
       "3                                      Gattaca (1997)   \n",
       "4                                Critical Care (1997)   \n",
       "5                       Wings of the Dove, The (1997)   \n",
       "6                                     Supercop (1992)   \n",
       "7                      FairyTale: A True Story (1997)   \n",
       "8                                    Breakdown (1997)   \n",
       "9                         George of the Jungle (1997)   \n",
       "10                                       Evita (1996)   \n",
       "11                           L.A. Confidential (1997)   \n",
       "12                         Tomorrow Never Dies (1997)   \n",
       "13                                        Babe (1995)   \n",
       "14                                 Restoration (1995)   \n",
       "15                             Full Monty, The (1997)   \n",
       "16                                   Dark City (1998)   \n",
       "17                          Desperate Measures (1998)   \n",
       "18                    Replacement Killers, The (1998)   \n",
       "19                           Leaving Las Vegas (1995)   \n",
       "20                                     Contact (1997)   \n",
       "21                           Starship Troopers (1997)   \n",
       "22  Paradise Lost: The Child Murders at Robin Hood...   \n",
       "23                                     Flipper (1996)   \n",
       "24                               Jungle2Jungle (1997)   \n",
       "\n",
       "                                 User: 579  \n",
       "0                         Star Wars (1977)  \n",
       "1                           Georgia (1995)  \n",
       "2             Bram Stoker's Dracula (1992)  \n",
       "3           Man of No Importance, A (1994)  \n",
       "4                      Blade Runner (1982)  \n",
       "5                          Maverick (1994)  \n",
       "6                  Muriel's Wedding (1994)  \n",
       "7                            Jaws 2 (1978)  \n",
       "8                     Little Odessa (1994)  \n",
       "9                           Go Fish (1994)  \n",
       "10                          Sleeper (1973)  \n",
       "11          Remains of the Day, The (1993)  \n",
       "12                        True Lies (1994)  \n",
       "13                       Just Cause (1995)  \n",
       "14                  Great Race, The (1965)  \n",
       "15                          Thinner (1996)  \n",
       "16                        Crow, The (1994)  \n",
       "17           Some Kind of Wonderful (1987)  \n",
       "18                       Free Willy (1993)  \n",
       "19                        Jane Eyre (1996)  \n",
       "20                       Unforgiven (1992)  \n",
       "21           Baby-Sitters Club, The (1995)  \n",
       "22  Beavis and Butt-head Do America (1996)  \n",
       "23                         Bad Boys (1995)  \n",
       "24              Princess Bride, The (1987)  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "export_name = json_input_filename + \".out\"\n",
    "s3.download_file(bucket_name, export_name, export_name)\n",
    "\n",
    "# Update DF rendering\n",
    "pd.set_option('display.max_rows', 30)\n",
    "with open(export_name) as json_file:\n",
    "    # Get the first line and parse it\n",
    "    line = json.loads(json_file.readline())\n",
    "    # Do the same for the other lines\n",
    "    while line:\n",
    "        # extract the user ID \n",
    "        col_header = \"User: \" + line['input']['userId']\n",
    "        # Create a list for all the movies\n",
    "        recommendation_list = []\n",
    "        # Add all the entries\n",
    "        for item in line['output']['recommendedItems']:\n",
    "            title = get_movie_title(item)\n",
    "            recommendation_list.append(title)\n",
    "        if 'bulk_recommendations_df' in locals():\n",
    "            new_rec_DF = pd.DataFrame(recommendation_list, columns = [col_header])\n",
    "            bulk_recommendations_df = bulk_recommendations_df.join(new_rec_DF)\n",
    "        else:\n",
    "            bulk_recommendations_df = pd.DataFrame(recommendation_list, columns=[col_header])\n",
    "        try:\n",
    "            line = json.loads(json_file.readline())\n",
    "        except:\n",
    "            line = None\n",
    "bulk_recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above you can see the various recommendations for the users provided, in a real scenario the list of users could be your entire userbase allowing you to quickly reference and compare results between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
